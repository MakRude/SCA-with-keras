{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data modules\n",
    "from numpy import empty, zeros, uint16\n",
    "from numpy.random import RandomState\n",
    "import numpy as np\n",
    "## load cw data\n",
    "import chipwhisperer as cw\n",
    "## load ASCAD data\n",
    "import h5py\n",
    "## load m4sc data\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unaltered code snippet taken from ASCAD_train_model\n",
    "\n",
    "#### ASCAD helper to load profiling and attack data (traces and labels)\n",
    "# Loads the profiling and attack datasets from the ASCAD\n",
    "# database\n",
    "def load_ascad(ascad_database_file, load_metadata=False):\n",
    "    check_file_exists(ascad_database_file)\n",
    "    # Open the ASCAD database HDF5 for reading\n",
    "    try:\n",
    "        in_file  = h5py.File(ascad_database_file, \"r\")\n",
    "    except:\n",
    "        print(\"Error: can't open HDF5 file '%s' for reading (it might be malformed) ...\" % ascad_database_file)\n",
    "        sys.exit(-1)\n",
    "    # Load profiling traces\n",
    "    X_profiling = np.array(in_file['Profiling_traces/traces'], dtype=np.int8)\n",
    "    # Load profiling labels\n",
    "    Y_profiling = np.array(in_file['Profiling_traces/labels'])\n",
    "    # Load attacking traces\n",
    "    X_attack = np.array(in_file['Attack_traces/traces'], dtype=np.int8)\n",
    "    # Load attacking labels\n",
    "    Y_attack = np.array(in_file['Attack_traces/labels'])\n",
    "    if load_metadata == False:\n",
    "        return (X_profiling, Y_profiling), (X_attack, Y_attack)\n",
    "    else:\n",
    "        return (X_profiling, Y_profiling), (X_attack, Y_attack), (in_file['Profiling_traces/metadata'], in_file['Attack_traces/metadata'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASCAD: Adapted by Mahmoud Gharra to fit the NTRU Prime input\n",
    "\n",
    "# returns traces and labels, as well as some important global meta_data\n",
    "def load_database_cw(my_database):\n",
    "    # load traces\n",
    "    print(\"++ Loading projects\")\n",
    "    project = cw.open_project(my_database)\n",
    "    global KEY_LENGTH, TEXT_LENGTH, SAMPLE_HIGH, TRAINING_SLICE, TEST_NUM, TEST_SLICE\n",
    "\n",
    "    # Organize trace data for MLP\n",
    "    print(\"++ Organizing traces\")\n",
    "    KEY_LENGTH = TEXT_LENGTH = project.keys[0].size\n",
    "\n",
    "    sample_low = 0\n",
    "    SAMPLE_HIGH = project.trace_manager().num_points() # length of singular trace\n",
    "    sample_slice = slice(sample_low, SAMPLE_HIGH)\n",
    "    sample_num = len(project.traces) # number of traces\n",
    "#     print(\"sample num: \", sample_num)\n",
    "    training_num = sample_num - tst_len\n",
    "    TRAINING_SLICE = slice(0, training_num)\n",
    "\n",
    "    TEST_NUM = sample_num - training_num\n",
    "    TEST_SLICE = slice(training_num, TEST_NUM + training_num)\n",
    "    assert TEST_NUM + training_num <= sample_num\n",
    "    assert training_num > 3*TEST_NUM\n",
    "\n",
    "    # organize traces in X matrix\n",
    "    X = empty(shape=(sample_num, SAMPLE_HIGH - sample_low))\n",
    "    for i in range(sample_num):\n",
    "        X[i] = project.waves[i][sample_slice]\n",
    "\n",
    "    # organize the operands in Y matrix\n",
    "    y = empty(shape=(sample_num, KEY_LENGTH))\n",
    "    for i in range(sample_num):\n",
    "        # reproduce values\n",
    "        y[i] = project.keys[i]\n",
    "        # These four lines caused a ton of issues in the past.\n",
    "        # I left them in to remind myself and who ever is reading this not to doubt themselves :p\n",
    "        # You're doing great simply by trying to be a better programmer and practicing your craft.\n",
    "        \n",
    "        # text_num = text_gen(seed=i)[:TEXT_LENGTH]\n",
    "        # key_num = key_gen(seed=i)[:KEY_LENGTH]\n",
    "        # y[i][:] = key_num[:]\n",
    "        # y[i][y[i] > 2**15] -= 2**16\n",
    "        \n",
    "        # In case you're wondering what the issue was in boring detail:\n",
    "        # The original script used the training seed to generate the data on the chip whisperer\n",
    "        # this meant, that you don't need to read out the labels (polynomial coefficients) but you need the seed to train the data\n",
    "        # This made the script unfit to handle new date sets.\n",
    "        \n",
    "    \n",
    "    # this is in case of little endian\n",
    "    y = np.array((y.T[1::2].T*(2**8)) + y.T[::2].T, dtype=np.int16)\n",
    "    KEY_LENGTH = TEXT_LENGTH = int(KEY_LENGTH/2)\n",
    "    \n",
    "    # transform generated key numbers to labels\n",
    "    unique = np.unique(y)\n",
    "    class_dic = dict([[unique[i], i] for i in range(len(unique))])\n",
    "    y_labelled = np.vectorize(class_dic.get)(y)\n",
    "    return X, y_labelled\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(X, y, key_idx, best_model):\n",
    "    # Load profiling traces\n",
    "    X_profiling = X[TRAINING_SLICE]\n",
    "    # Load profiling labels\n",
    "    Y_profiling = y[TRAINING_SLICE, key_idx]\n",
    "    # Load testing traces\n",
    "    X_testing = X[TEST_SLICE]\n",
    "    ## make sure input data has correct shape (this part was adapted from ASCAD code as we need to do the exact same thing here)\n",
    "    input_layer_shape = best_model.get_layer(index=0).input_shape\n",
    "    # Adapt the data shape according our model input\n",
    "    if len(input_layer_shape) == 2:\n",
    "        # This is a MLP\n",
    "        X_testing = X[TEST_SLICE, :]\n",
    "    elif len(input_layer_shape) == 3:\n",
    "        # This is a CNN: reshape the data\n",
    "        X_testing = X[TEST_SLICE, :]\n",
    "        X_testing = X_testing.reshape((X_testing.shape[0], X_testing.shape[1], 1))\n",
    "    else:\n",
    "        print(\"Error: model input shape length %d is not expected ...\" % len(input_layer_shape))\n",
    "        sys.exit(-1)\n",
    "    # Load testing labels\n",
    "    Y_testing = y[TEST_SLICE, key_idx]\n",
    "    return (X_profiling, Y_profiling), (X_testing, Y_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASCAD: Adapted by Mahmoud Gharra to fit the Gaussian Sampler input\n",
    "\n",
    "\n",
    "# returns traces and labels, as well as some important global meta_data\n",
    "\n",
    "def load_database_gauss(my_database):\n",
    "    # load traces\n",
    "    print(\"++ Loading projects\")\n",
    "    project = cw.open_project(my_database)\n",
    "    global KEY_LENGTH, TEXT_LENGTH, SAMPLE_HIGH, TRAINING_SLICE, TEST_NUM, TEST_SLICE\n",
    "\n",
    "    # Organize trace data for MLP\n",
    "    print(\"++ Organizing traces\")\n",
    "    KEY_LENGTH = TEXT_LENGTH = len(project.keys[0]) * 8\n",
    "    print(\"KEY_LENGTH: {}\".format(KEY_LENGTH))\n",
    "    print(\"project.keys[0][0]: {}\".format(project.keys[0][0]))\n",
    "    print(\"np.asarray(bytearray(project.keys[0]))\", np.asarray(bytearray(project.keys[0])))\n",
    "\n",
    "    # SET DATA RELATED GLOBALS REQUIRED FOR EXTRACTION\n",
    "    sample_low = 0\n",
    "    SAMPLE_HIGH = project.trace_manager().num_points() # length of singular trace\n",
    "    sample_slice = slice(sample_low, SAMPLE_HIGH)\n",
    "    sample_num = len(project.traces) # number of traces\n",
    "#     print(\"sample num: \", sample_num)\n",
    "    \n",
    "    # organize traces in X and Y matrices\n",
    "    # count is used to count traces with wrong label length (some labels displayed a length of 31, it is as of the formulation of this comment unclear, why that happens)\n",
    "    count = 0\n",
    "\n",
    "    X = empty(shape=(sample_num, SAMPLE_HIGH - sample_low))\n",
    "    y = empty(shape=(sample_num, KEY_LENGTH))\n",
    "\n",
    "    for i in range(sample_num):\n",
    "        # reproduce values\n",
    "        \n",
    "        # The next three lines were for debugging purposes. I'm sorry for doing printf debugging :p\n",
    "#         print(\"key of sample {}: {}\".format(i, project.keys[i]))\n",
    "#         print(\"data type of key of sample {}: {}\".format(i, type(project.keys[i])))\n",
    "#         print(\"ISO-8859-1 encoding: {}\".format(project.keys[i].decode(\"ISO-8859-1\")))\n",
    "    \n",
    "        # seeing as some of the traces appear to to have labels of the wrong length, I've elected to remove them\n",
    "        if (len(np.asarray(bytearray(project.keys[i])))) is not int(KEY_LENGTH/8):\n",
    "            count += 1\n",
    "            print(\"Number of problematic traces raised to: {}\".format(count))\n",
    "            continue\n",
    "            \n",
    "        # we subtract count because we're trying to fill in for the wrong traces\n",
    "#         y[i-count] = np.asarray(bytearray(project.keys[i]))\n",
    "        y[i-count] = np.asarray([int(char) for char in ''.join(['{0:08b}'.format(ff) for ff in np.asarray(bytearray(project.keys[0]))])])\n",
    "\n",
    "        X[i-count] = project.waves[i][sample_slice]\n",
    "\n",
    "#     remove last {count} rows for having wrong KEY-Dimesions\n",
    "    if i is not 0:\n",
    "        y = y[0:-count]\n",
    "        X = X[0:-count]\n",
    "\n",
    "        \n",
    "    # SET DATA RELATED GLOBALS before returning (POST EXTRACTION)\n",
    "    sample_low = 0\n",
    "    SAMPLE_HIGH = project.trace_manager().num_points() # length of singular trace\n",
    "    sample_slice = slice(sample_low, SAMPLE_HIGH)\n",
    "    sample_num = len(project.traces) - count # number of traces\n",
    "    \n",
    "    training_num = sample_num - tst_len\n",
    "    TRAINING_SLICE = slice(0, training_num)\n",
    "\n",
    "    TEST_NUM = sample_num - training_num\n",
    "    TEST_SLICE = slice(training_num, TEST_NUM + training_num)\n",
    "    assert TEST_NUM + training_num <= sample_num\n",
    "    assert training_num > 3*TEST_NUM\n",
    "\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASCAD: Adapted by Mahmoud Gharra to fit the Gaussian Sampler input\n",
    "\n",
    "\n",
    "# returns traces and labels, as well as some important global meta_data\n",
    "\n",
    "def load_database_dpa_contest(my_database):\n",
    "    # load traces\n",
    "    print(\"++ Loading projects\")\n",
    "    X = np.load(my_database + \"/traces.npy\")\n",
    "    y_init = np.load(my_database + \"/labels_pt.npy\")\n",
    "    print(\"y_init: {}\".format(y_init))\n",
    "    print(\"y_init[:]: {}\".format(y_init[:,0]))\n",
    "    \n",
    "    y = np.array([[int(x) for x in '{:08b}'.format(int(input_init))] for input_init in y_init[:,0]])\n",
    "    \n",
    "    global KEY_LENGTH, TEXT_LENGTH, SAMPLE_HIGH, TRAINING_SLICE, TEST_NUM, TEST_SLICE\n",
    "\n",
    "    # Organize trace data for MLP\n",
    "    print(\"++ Organizing traces\")\n",
    "    KEY_LENGTH = TEXT_LENGTH = 4\n",
    "#     KEY_LENGTH = TEXT_LENGTH = 16\n",
    "    print(\"KEY_LENGTH: {}\".format(KEY_LENGTH))\n",
    "    \n",
    "    # SET DATA RELATED GLOBALS REQUIRED FOR EXTRACTION\n",
    "    sample_low = 0\n",
    "#     print(\"X: \", X)\n",
    "#     print(\"X.shape: \", X.shape)\n",
    "    SAMPLE_HIGH = X.shape[1] # length of singular trace\n",
    "    sample_slice = slice(sample_low, SAMPLE_HIGH)\n",
    "    sample_num = X.shape[0] # number of traces\n",
    "#     print(\"sample num: \", sample_num)\n",
    "    \n",
    "    training_num = sample_num - tst_len\n",
    "    TRAINING_SLICE = slice(0, training_num)\n",
    "\n",
    "    TEST_NUM = sample_num - training_num\n",
    "    TEST_SLICE = slice(training_num, TEST_NUM + training_num)\n",
    "    assert TEST_NUM + training_num <= sample_num\n",
    "    assert training_num > 3*TEST_NUM\n",
    "\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these functions were used in the loading of m4sc data\n",
    "\n",
    "def bit8(i):\n",
    "    return [(0 if (0 == (i & (1 << j))) else 1) for j in range(8)]\n",
    "\n",
    "def concatBits(a, b):\n",
    "    return 2*a + b\n",
    "\n",
    "def chunk4(i):\n",
    "    temp = bit8(i)\n",
    "    return [concatBits(temp[2*i], temp[2*i + 1]) for i in range(4)]\n",
    "\n",
    "def bit16(i):\n",
    "#     return [(0 if (0 == (i & (1 << j))) else 1) for j in range(15, -1, -1)]\n",
    "    return [(0 if (0 == (i & (1 << j))) else 1) for j in range(16)]\n",
    "\n",
    "def bit368(i):\n",
    "    return [(0 if (0 == (i & (1 << j))) else 1) for j in range(368)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASCAD: Adapted by Mahmoud Gharra to fit m4sc input\n",
    "\n",
    "\n",
    "# returns traces and labels, as well as some important global meta_data\n",
    "\n",
    "def load_database_m4sc(my_database):\n",
    "\n",
    "    # load traces\n",
    "    print(\"++ Loading schoolbook on m4sc data\")\n",
    "    \n",
    "    data = []\n",
    "    data_file = my_database\n",
    "    with open(data_file, 'rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                data.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                break\n",
    "\n",
    "    # parse traces - convert int array to bit array\n",
    "    print(\"++ Parse m4sc data\")\n",
    "    X = np.array([i[4] for i in data])\n",
    "    y_init = np.array([int((int(i[0][-2:], 16))) for i in data])\n",
    "    y = np.array([chunk4(i) for i in y_init], dtype=np.uint8)\n",
    "    print(\"++ Finished parsing m4sc data\")\n",
    "\n",
    "    print(\"++ Normalizing traces of m4sc\")\n",
    "    X = X - X.mean()\n",
    "    X = X / X.max()\n",
    "    \n",
    "    global KEY_LENGTH, TEXT_LENGTH, SAMPLE_HIGH, TRAINING_SLICE, TEST_NUM, TEST_SLICE\n",
    "\n",
    "    # Organize trace data for network\n",
    "    print(\"++ Organizing traces\")\n",
    "#     KEY_LENGTH = TEXT_LENGTH = 1\n",
    "    KEY_LENGTH = TEXT_LENGTH = 4\n",
    "    print(\"KEY_LENGTH: {}\".format(KEY_LENGTH))\n",
    "    \n",
    "    # SET DATA RELATED GLOBALS REQUIRED FOR EXTRACTION\n",
    "    sample_low = 0\n",
    "    print(\"X: \", X)\n",
    "    print(\"X.shape: \", X.shape)\n",
    "    print(\"y: \", y)\n",
    "    print(\"y.shape: \", y.shape)\n",
    "    \n",
    "    SAMPLE_HIGH = X.shape[1] # length of singular trace\n",
    "    sample_slice = slice(sample_low, SAMPLE_HIGH)\n",
    "    sample_num = X.shape[0] # number of traces\n",
    "#     print(\"sample num: \", sample_num)\n",
    "    \n",
    "    training_num = sample_num - tst_len\n",
    "    TRAINING_SLICE = slice(0, training_num)\n",
    "\n",
    "    TEST_NUM = sample_num - training_num\n",
    "    TEST_SLICE = slice(training_num, TEST_NUM + training_num)\n",
    "    assert TEST_NUM + training_num <= sample_num\n",
    "    assert training_num > 3*TEST_NUM\n",
    "\n",
    "\n",
    "    return X, y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
